import streamlit as st
import pdfplumber
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="pdfminer")
import docx
import re
import os
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import chromadb
import csv

# ===== CONFIG GEMINI KEY =====
# Äiá»n key Gemini cá»§a báº¡n vÃ o Ä‘Ã¢y â†“â†“â†“
GEMINI_API_KEY = "AIzaSyCSenmJGRf2VJ9WId1SwQpfL3dMRRaHWmw"
genai.configure(api_key=GEMINI_API_KEY)

# ===== RUBRIC =====
rubric = """
TiÃªu chÃ­ cháº¥m Ä‘iá»ƒm thuá»™c lÄ©nh vá»±c CÃ´ng nghá»‡ thÃ´ng tin. Tá»•ng Ä‘iá»ƒm tá»‘i Ä‘a lÃ  10 Ä‘iá»ƒm, chia thÃ nh 5 nhÃ³m tiÃªu chÃ­ chÃ­nh:
1. Ná»™i dung vÃ  kiáº¿n thá»©c chuyÃªn mÃ´n (4.5 Ä‘iá»ƒm)
2. Cáº¥u trÃºc vÃ  tá»• chá»©c bÃ i viáº¿t (2 Ä‘iá»ƒm)
3. TrÃ¬nh bÃ y vÃ  diá»…n Ä‘áº¡t (1.5 Ä‘iá»ƒm)
4. PhÃ¢n tÃ­ch, láº­p luáº­n vÃ  giáº£i thÃ­ch (1.5 Ä‘iá»ƒm)
5. TÃ i liá»‡u tham kháº£o vÃ  trÃ­ch dáº«n (0.5 Ä‘iá»ƒm)
NgoÃ i ra cÃ³ tiÃªu chÃ­ trá»« Ä‘iá»ƒm náº¿u bÃ i lÃ m vi pháº¡m yÃªu cáº§u nghiÃªm trá»ng.

TiÃªu chÃ­ 1 â€“ Ná»™i dung vÃ  kiáº¿n thá»©c chuyÃªn mÃ´n (4.5 Ä‘iá»ƒm):
â€¢ ÄÃ¡p á»©ng yÃªu cáº§u Ä‘á» bÃ i (1.5 Ä‘iá»ƒm): bÃ i lÃ m Ä‘Ãºng trá»ng tÃ¢m, khÃ´ng láº¡c Ä‘á», bao quÃ¡t Ä‘á»§ cÃ¡c khÃ­a cáº¡nh.
â€¢ TÃ­nh chÃ­nh xÃ¡c kiáº¿n thá»©c (2 Ä‘iá»ƒm): ná»™i dung Ä‘Ãºng, khÃ´ng sai nghiÃªm trá»ng vá» lÃ½ thuyáº¿t, thuáº­t toÃ¡n, phÆ°Æ¡ng phÃ¡p.
â€¢ TÃ­nh sÃ¡ng táº¡o vÃ  thá»±c tiá»…n (1 Ä‘iá»ƒm): cÃ³ tiáº¿p cáº­n má»›i, váº­n dá»¥ng thá»±c táº¿, cÃ³ dáº«n chá»©ng rÃµ.

TiÃªu chÃ­ 2 â€“ Cáº¥u trÃºc vÃ  tá»• chá»©c bÃ i viáº¿t (2 Ä‘iá»ƒm):
â€¢ Cáº¥u trÃºc (1.2 Ä‘iá»ƒm): bÃ i gá»“m má»Ÿ bÃ i, thÃ¢n bÃ i, káº¿t luáº­n; bá»‘ cá»¥c rÃµ rÃ ng, khÃ´ng rá»i ráº¡c.
â€¢ Logic liÃªn káº¿t (0.8 Ä‘iá»ƒm): cÃ¡c Ã½ ná»‘i liá»n máº¡ch, cÃ³ sá»­ dá»¥ng tá»« ná»‘i Ä‘á»ƒ giá»¯ tÃ­nh liÃªn tá»¥c.

TiÃªu chÃ­ 3 â€“ TrÃ¬nh bÃ y vÃ  diá»…n Ä‘áº¡t (1.5 Ä‘iá»ƒm):
â€¢ NgÃ´n ngá»¯ chuyÃªn ngÃ nh (0.6 Ä‘iá»ƒm): sá»­ dá»¥ng Ä‘Ãºng thuáº­t ngá»¯ CNTT, trÃ¡nh cÃ¡ch nÃ³i Ä‘Æ¡n giáº£n hÃ³a.
â€¢ ChÃ­nh táº£, ngá»¯ phÃ¡p (0.6 Ä‘iá»ƒm): khÃ´ng máº¯c lá»—i nghiÃªm trá»ng, diá»…n Ä‘áº¡t máº¡ch láº¡c.
â€¢ HÃ¬nh thá»©c trÃ¬nh bÃ y (0.3 Ä‘iá»ƒm): rÃµ rÃ ng, khoa há»c, cÃ³ sá»‘ trang/má»¥c lá»¥c náº¿u cáº§n.

TiÃªu chÃ­ 4 â€“ PhÃ¢n tÃ­ch, láº­p luáº­n vÃ  giáº£i thÃ­ch (1.5 Ä‘iá»ƒm):
â€¢ Láº­p luáº­n cháº·t cháº½ (0.7 Ä‘iá»ƒm): cÃ³ cÆ¡ sá»Ÿ rÃµ rÃ ng, giáº£i thÃ­ch há»£p lÃ½.
â€¢ VÃ­ dá»¥, dáº«n chá»©ng (0.5 Ä‘iá»ƒm): cÃ³ minh há»a báº±ng thá»±c táº¿, sÆ¡ Ä‘á»“ hoáº·c thuáº­t toÃ¡n.
â€¢ Pháº£n biá»‡n, Ä‘Ã¡nh giÃ¡ (0.3 Ä‘iá»ƒm): Ä‘Æ°a nhiá»u gÃ³c nhÃ¬n, so sÃ¡nh giáº£i phÃ¡p khÃ¡c nhau.

TiÃªu chÃ­ 5 â€“ TÃ i liá»‡u tham kháº£o vÃ  trÃ­ch dáº«n (0.5 Ä‘iá»ƒm):
â€¢ TÃ i liá»‡u cháº¥t lÆ°á»£ng (0.3 Ä‘iá»ƒm): cÃ³ nguá»“n gá»‘c rÃµ rÃ ng, chÃ­nh thá»‘ng.
â€¢ TrÃ­ch dáº«n Ä‘Ãºng chuáº©n (0.2 Ä‘iá»ƒm): theo quy chuáº©n nhÆ° APA, IEEE, Harvard...

TiÃªu chÃ­ trá»« Ä‘iá»ƒm:
â€¢ Láº¡c Ä‘á» hoáº·c sai nghiÃªm trá»ng vá» kiáº¿n thá»©c: trá»« toÃ n bá»™ Ä‘iá»ƒm pháº§n ná»™i dung.
â€¢ TrÃ¬nh bÃ y quÃ¡ sÆ¡ sÃ i, khÃ´ng cÃ³ cáº¥u trÃºc rÃµ rÃ ng: trá»« tá»‘i Ä‘a 2 Ä‘iá»ƒm.
â€¢ Viáº¿t sai chÃ­nh táº£, ngá»¯ phÃ¡p quÃ¡ nhiá»u: trá»« tá»‘i Ä‘a 1 Ä‘iá»ƒm.
â€¢ KhÃ´ng trÃ­ch nguá»“n nhÆ°ng dÃ¹ng tÃ i liá»‡u ngoÃ i: trá»« 0.5 Ä‘iá»ƒm.
"""

# Load embedding model
embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Chroma vector DB setup
chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection("essays")

# dá»¯ liá»‡u ná»n => nhá»¯ng file máº«u (pdf, docx, txt)

# HÃ m export collection ra CSV dá»± phÃ²ng (UTF-8 with BOM, metadata tÃ¡ch cá»™t)
def export_collection_to_csv(collection, file_path="essays_backup.csv"):
    all_data = collection.get()
    with open(file_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        # Header
        writer.writerow(["id", "document", "course", "category", "filename", "basename"])
        
        for i in range(len(all_data["ids"])):
            metadata = all_data["metadatas"][i] if "metadatas" in all_data else {}
            writer.writerow([
                all_data["ids"][i],
                all_data["documents"][i],
                metadata.get("course", ""),
                metadata.get("category", ""),
                metadata.get("filename", ""),
                metadata.get("basename", "")
            ])


def load_sample_data():
    base_folder = "data"

    docs, ids, metadatas = [], [], []

    # Duyá»‡t qua tá»«ng mÃ´n há»c
    if not os.path.exists(base_folder):
        os.makedirs(base_folder)

    for course in os.listdir(base_folder):
        course_path = os.path.join(base_folder, course)
        if not os.path.isdir(course_path):
            continue  # bá» qua file láº», chá»‰ láº¥y folder mÃ´n há»c

        # CÃ¡c thÆ° má»¥c con: essays, scores, teaching_materials
        for category in ["essays", "scores", "teaching_materials"]:
            folder_path = os.path.join(course_path, category)
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)  # táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³

            for idx, filename in enumerate(os.listdir(folder_path)):
                path = os.path.join(folder_path, filename)
                text = ""

                # Äá»c file txt
                if filename.endswith(".txt"):
                    with open(path, "r", encoding="utf-8") as f:
                        text = f.read()

                # Äá»c file pdf
                elif filename.endswith(".pdf"):
                    with pdfplumber.open(path) as pdf:
                        for page in pdf.pages:
                            page_text = page.extract_text()
                            if page_text:
                                text += page_text + "\n"

                # Äá»c file docx
                elif filename.endswith(".docx"):
                    doc = docx.Document(path)
                    text = "\n".join([para.text for para in doc.paragraphs])

                else:
                    continue  # bá» qua Ä‘á»‹nh dáº¡ng khÃ´ng há»— trá»£

                if text.strip():
                    basename = os.path.splitext(filename)[0]
                    docs.append(text)
                    ids.append(f"{course}_{category}_{idx}")
                    metadatas.append({
                        "course": course,
                        "category": category,
                        "filename": filename,
                        "basename": basename
                    })

    # ThÃªm vÃ o vector DB
    if docs:
        embeddings = embedding_model.encode(docs).tolist()
        collection.add(documents=docs, ids=ids, embeddings=embeddings, metadatas=metadatas)
        export_collection_to_csv(collection, "essays_backup.csv")

# Load ngay khi khá»Ÿi Ä‘á»™ng app
load_sample_data()


# ===== FUNCTIONS =====
def read_file(file):
    if file.name.endswith(".pdf"):
        text = ""
        with pdfplumber.open(file) as pdf:
            for page in pdf.pages:
                text += page.extract_text() + "\n"
        return text
    elif file.name.endswith(".docx"):
        doc = docx.Document(file)
        return "\n".join([para.text for para in doc.paragraphs])
    elif file.name.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return ""

def save_result_to_excel(course, filename, essay_text, score, file_path="grading_results.xlsx"):
    from openpyxl import Workbook, load_workbook
    
    #  Chá»‰ láº¥y 300 kÃ½ tá»± Ä‘áº§u tiÃªn
    essay_preview = essay_text[:300] + ("..." if len(essay_text) > 300 else "")
    
    if os.path.exists(file_path):
        wb = load_workbook(file_path)
        ws = wb.active
    else:
        wb = Workbook()
        ws = wb.active
        ws.append(["TÃªn mÃ´n há»c", "TÃªn file", "Ná»™i dung bÃ i luáº­n", "Äiá»ƒm"])

    ws.append([course, filename, essay_preview, score])
    wb.save(file_path)


def find_relevant_docs(query):
    query_embedding = embedding_model.encode([query]).tolist()
    results = collection.query(query_embeddings=query_embedding, n_results=1)
    return results['documents'][0][0] if results['documents'] else ""

def grade_essay(essay_text, course_context, sample_text):
    model = genai.GenerativeModel("gemini-1.5-flash")
    prompt = f"""
Báº¡n lÃ  giáº£ng viÃªn Ä‘áº¡i há»c. HÃ£y cháº¥m bÃ i luáº­n cá»§a sinh viÃªn theo thang Ä‘iá»ƒm 10.

HÃ£y cháº¥m Ä‘iá»ƒm bÃ i luáº­n dÆ°á»›i Ä‘Ã¢y dá»±a trÃªn bá»™ tiÃªu chÃ­ sau: {rubric}
YÃªu cáº§u:
1. Cháº¥m tá»«ng tiÃªu chÃ­ kÃ¨m Ä‘iá»ƒm sá»‘.
2. TÃ­nh tá»•ng Ä‘iá»ƒm cuá»‘i cÃ¹ng.
3. ÄÆ°a ra nháº­n xÃ©t chi tiáº¿t, chá»‰ ra Ä‘iá»ƒm máº¡nh vÃ  Ä‘iá»ƒm cáº§n cáº£i thiá»‡n.

Ngá»¯ cáº£nh mÃ´n há»c: {course_context}
Ngá»¯ cáº£nh sinh viÃªn: {student_context}
BÃ i máº«u tham chiáº¿u: {sample_text}
BÃ i luáº­n cáº§n cháº¥m: {essay_text}

Tráº£ vá»:
- Äiá»ƒm tá»•ng (0-10)
- Nháº­n xÃ©t chi tiáº¿t
"""
    response = model.generate_content(prompt)
    return response.text

def extract_score(result_text: str) -> str:
    import re
    score_value = "?"
    # Æ¯u tiÃªn cÃ¡c dÃ²ng chá»©a tá»« khÃ³a
    for line in result_text.splitlines():
        if any(kw in line for kw in ["Äiá»ƒm tá»•ng", "Tá»•ng Ä‘iá»ƒm", "Äiá»ƒm cuá»‘i cÃ¹ng"]):
            match = re.search(r"(\d+(\.\d+)?)", line)
            if match:
                score_value = match.group(1)
            break

    # Fallback: tÃ¬m sá»‘ trong toÃ n bá»™ vÄƒn báº£n
    if score_value == "?":
        matches = re.findall(r"(\d+(\.\d+)?)", result_text)
        candidates = [float(m[0]) for m in matches]
        candidates = [c for c in candidates if 0 <= c <= 10]
        if candidates:
            score_value = str(max(candidates))

    return score_value


# ===== STREAMLIT UI =====
st.set_page_config(page_title="Cháº¥m Ä‘iá»ƒm bÃ i luáº­n", page_icon="ğŸ“„", layout="wide")

# CSS
st.markdown("""
    <style>
    .main {
        background-color: #f9fafc;
    }
    .stTitle {
        font-size: 28px !important;
        color: #1a237e;
        font-weight: bold;
    }
    .score-box {
        padding: 20px;
        border-radius: 12px;
        background-color: #e3f2fd;
        text-align: center;
        margin-bottom: 20px;
    }
    .score-text {
        font-size: 48px;
        font-weight: bold;
        color: #0d47a1;
    }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ“„ Há»‡ thá»‘ng cháº¥m Ä‘iá»ƒm bÃ i luáº­n tá»± Ä‘á»™ng")

# Layout
col1, col2 = st.columns([1, 2])

with col1:
    st.header("ğŸ“‚ Nháº­p dá»¯ liá»‡u")
    uploaded_file = st.file_uploader("Táº£i lÃªn bÃ i luáº­n (.pdf, .docx, .txt)", type=["pdf", "docx", "txt"])
    course_context = st.selectbox("ğŸ“˜ MÃ´n há»c", ["ThÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­", "PhÃ¡t triá»ƒn á»©ng dá»¥ng giao diá»‡n", "Há»‡ thá»‘ng thanh toÃ¡n trong thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­", "Chiáº¿n lÆ°á»£c thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­"])
    year = st.selectbox("ğŸ“ NÄƒm há»c", ["NÄƒm 1: Sinh viÃªn chá»‰ má»›i lÃ m quen viáº¿t luáº­n. ÄÃ¡nh giÃ¡ chá»§ yáº¿u á»Ÿ sá»± rÃµ rÃ ng, logic cÆ¡ báº£n, cÃ¡ch trÃ¬nh bÃ y Ã½ tÆ°á»Ÿng. KhÃ´ng yÃªu cáº§u nhiá»u vá» trÃ­ch dáº«n há»c thuáº­t hay cáº¥u trÃºc phá»©c táº¡p.", "NÄƒm 2: Sinh viÃªn báº¯t Ä‘áº§u há»c ká»¹ nÄƒng viáº¿t nÃ¢ng cao hÆ¡n. Cáº§n cÃ³ cáº¥u trÃºc 3 pháº§n (má»Ÿ bÃ i â€“ thÃ¢n bÃ i â€“ káº¿t luáº­n), biáº¿t triá»ƒn khai luáº­n Ä‘iá»ƒm theo Ä‘oáº¡n vÄƒn máº¡ch láº¡c, cÃ³ vÃ­ dá»¥ minh há»a cÆ¡ báº£n.", "NÄƒm 3: Sinh viÃªn pháº£i thá»ƒ hiá»‡n láº­p luáº­n cháº·t cháº½ hÆ¡n, biáº¿t sá»­ dá»¥ng tÃ i liá»‡u tham kháº£o (trÃ­ch dáº«n Ä‘Ãºng cÃ¡ch), trÃ¬nh bÃ y theo chuáº©n há»c thuáº­t, cÃ³ phÃ¢n tÃ­ch, so sÃ¡nh, Ä‘Ã¡nh giÃ¡ thay vÃ¬ chá»‰ mÃ´ táº£.", "NÄƒm 4: Sinh viÃªn cáº§n Ä‘áº¡t chuáº©n luáº­n vÄƒn tá»‘t nghiá»‡p: viáº¿t há»c thuáº­t hoÃ n chá»‰nh, cÃ³ Ä‘áº·t váº¥n Ä‘á» â€“ cÆ¡ sá»Ÿ lÃ½ thuyáº¿t â€“ phÆ°Æ¡ng phÃ¡p â€“ phÃ¢n tÃ­ch â€“ káº¿t quáº£ â€“ káº¿t luáº­n, sá»­ dá»¥ng trÃ­ch dáº«n chuáº©n, thá»ƒ hiá»‡n tÆ° duy nghiÃªn cá»©u Ä‘á»™c láº­p vÃ  Ä‘Ã³ng gÃ³p má»›i."])
    faculty = st.selectbox("ğŸ« Khoa", ["CÃ´ng nghá»‡ thÃ´ng tin kinh doanh", "Quáº£n trá»‹ kinh doanh", "Marketing"])
    student_context = f"Sinh viÃªn {year} thuá»™c Khoa {faculty}"

    if st.button("ğŸš€ Cháº¥m Ä‘iá»ƒm", use_container_width=True):
        if uploaded_file is not None:
            essay_text = read_file(uploaded_file)
            if not essay_text.strip():
                st.error("âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c ná»™i dung tá»« file.")
            else:
                sample_text = find_relevant_docs(essay_text)
                result = grade_essay(essay_text, course_context, sample_text)
                st.session_state["grading_result"] = result
                
                score_value = extract_score(result)

                # LÆ°u káº¿t quáº£ vÃ o Excel
                save_result_to_excel(course_context, uploaded_file.name, essay_text, score_value)
                st.success(f"âœ… Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o grading_results.xlsx (Äiá»ƒm: {score_value})")
        else:
            st.warning("âš ï¸ Vui lÃ²ng táº£i lÃªn bÃ i luáº­n trÆ°á»›c.")

with col2:
    st.header("ğŸ“Š Káº¿t quáº£ cháº¥m Ä‘iá»ƒm")
    if "grading_result" in st.session_state:
        result_text = st.session_state["grading_result"]
        score_value = extract_score(result_text)
        st.markdown(f"""
            <div class="score-box">
                <div style="color: #000">Äiá»ƒm tá»•ng</div>
                <div class="score-text">{score_value}</div>
            </div>
        """, unsafe_allow_html=True)

        st.subheader("ğŸ“ Nháº­n xÃ©t chi tiáº¿t")
        st.write(result_text)
    else:
        st.info("ğŸ‘‰ Káº¿t quáº£ sáº½ hiá»ƒn thá»‹ táº¡i Ä‘Ã¢y sau khi cháº¥m Ä‘iá»ƒm.")

# ===== QUáº¢N LÃ CORPUS =====
st.markdown("---")
st.header("ğŸ“‚ Quáº£n lÃ½ Corpus")

if st.button("ğŸ”„ LÃ m má»›i dá»¯ liá»‡u corpus"):
    load_sample_data()
    st.success("Dá»¯ liá»‡u corpus Ä‘Ã£ Ä‘Æ°á»£c lÃ m má»›i.")

all_data = collection.get()
if all_data and all_data["ids"]:
    import pandas as pd
    rows = []
    for i in range(len(all_data["ids"])):
        meta = all_data["metadatas"][i] if "metadatas" in all_data else {}
        rows.append({
            "id": all_data["ids"][i],
            "course": meta.get("course", ""),
            "category": meta.get("category", ""),
            "filename": meta.get("filename", ""),
            "basename": meta.get("basename", ""),
            "preview": all_data["documents"][i][:200] + "..."
        })
    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True)

    selected_id = st.selectbox("ğŸ” Xem ná»™i dung chi tiáº¿t theo ID:", df["id"])
    if selected_id:
        idx = df.index[df["id"] == selected_id][0]
        st.subheader(f"ğŸ“„ Ná»™i dung chi tiáº¿t cá»§a `{df.at[idx, 'filename']}`")
        st.text_area("Document", all_data["documents"][idx], height=300)
else:
    st.info("ğŸ“­ ChÆ°a cÃ³ dá»¯ liá»‡u corpus. Vui lÃ²ng thÃªm file vÃ o thÆ° má»¥c `data/` vÃ  lÃ m má»›i.")